---
title: "[01] AWS 자격증 취득하기: SA - Associate"
created: 2023-01-28 18:00:00 +0900
updated: 2023-02-24 22:00:00 +0900
author: namu
categories: cloud
permalink: "/cloud/:year/:month/:day/:title"
image: https://d2908q01vomqb2.cloudfront.net/9109c85a45b703f87f1413a405549a2cea9ab556/2021/04/14/social-image-ML-1243x630.png
image-view: true
image-author: amazon.com
image-source: https://aws.amazon.com/ko/blogs/training-and-certification/learn-how-to-operationalize-ml-models-with-new-aws-course/
---

---

### 목차

- [개념 정리](#개념-정리)
    - [IAM policy](#iam-policy), [IAM role](#iam-role), [권한 경계(Permissions Boundary)](#권한-경계permissions-boundary),
    [신뢰 정책(Trust Policy)](#신뢰-정책trust-policy)
    - [EC2 관련](#ec2-관련)
    - [S3 및 기타 스토리지](#s3-및-기타-스토리지)
    - [글로벌-전송](#글로벌-전송)
    - [데이터베이스](#데이터베이스)

### 시리즈

- <a href="{{ site.github.url }}/cloud/2023/02/24/aws-certificate02" target="_blank">
[02] AWS 자격증 취득하기: SA - Associate</a>

- <a href="{{ site.github.url }}/cloud/2021/09/18/aws-terminologies" target="_blank">
[01][AWS 퍼블릭클라우드 실습] 용어 정리</a>
- <a href="{{ site.github.url }}/cloud/2021/09/18/build-cloud-infra-with-aws01" target="_blank">
[02][AWS 퍼블릭클라우드 실습] VPC 구축</a>
- <a href="{{ site.github.url }}/cloud/2021/10/17/build-cloud-infra-with-aws02" target="_blank">
[03][AWS 퍼블릭클라우드 실습] EC2 생성</a>

### 참조

- <a href="https://aws.amazon.com/ko/training/learn-about/architect/?la=sec&sec=role" target="_blank">
AWS: training page of SA(Solutions Architect)</a>
- <a href="https://www.inflearn.com/course/aws-%EC%9E%90%EA%B2%A9%EC%A6%9D-%EC%96%B4%EC%86%8C%EC%8B%9C%EC%97%90%EC%9D%B4%ED%8A%B8" target="_blank">
인프런 강의(코드바나나님): AWS Certified Solutions Architect - Associate 자격증 준비하기</a>

---

<br>
## 들어가며

신년을 맞아 **<a href="https://aws.amazon.com/ko/certification/benefits/" target="_blank">AWS 자격증 배지</a>**를 
달아보자는 목표를 세웠습니다.

그 중 퍼블릭 클라우드 인프라 전반에 대한 기본적인 이해를 요구하는<br>
**<a href="https://aws.amazon.com/ko/certification/certified-solutions-architect-associate/?ch=sec&sec=rmg&d=1"
target="_blank">Solutions Architect: Associate</a>** 를 취득하기로 정했습니다.

사실 작년동안 회사 내 여러 프로젝트를 진행하며 AWS 퍼블릭 클라우드 인프라를 계속 다뤄왔습니다.

이번 시험을 준비하며 알고있던 개념들을 체계적으로 정리하고, 몰랐던 세부내용까지 학습할 예정입니다.
본 글에서는 부분적으로 알았거나 새로 배운 서비스 위주로 기술하겠습니다.

> **인프런 <a href="https://www.inflearn.com/course/aws-%EC%9E%90%EA%B2%A9%EC%A6%9D-%EC%96%B4%EC%86%8C%EC%8B%9C%EC%97%90%EC%9D%B4%ED%8A%B8" target="_blank">
AWS Certified Solutions Architect - Associate 자격증 준비하기</a> 강의를 참조했습니다.**

> **"[실전]" 키워드가 달린 부분은 실전문제풀이 이후 출제된 문제 관점에서 개념을 추가로 정리한 내용입니다.**

<br>
## 개념 정리

### IAM policy

IAM 정책은 **Json 포맷**으로 이루어집니다.

정책 내에 **Statement** 는 여러 개 있을 수 있고, 구문이 나열된 순서대로 축적되며 적용됩니다.<br>
statement 간 충돌이 있을 경우 나중에 배치된 구문이 적용됩니다.

커스텀 정책은 **IAM 사용자**, **IAM 그룹** 혹은 **IAM 역할(role)**에 각각 지정할 수 있습니다.<br>
AWS 에는 사전에 정의된 다양한 정책이 존재하므로, 검색을 통해 적절히 활용할 수 있습니다.

**<a href="https://awspolicygen.s3.amazonaws.com/policygen.html" target="_blank">AWS Policy Generator</a>**
를 활용해 보다 손쉽게 정책을 생성할 수 있습니다.

<br>
### IAM role

**역할(role)**은 **IAM 사용자**, **IAM 그룹**과 더불어 정책을 구성하는 단위로 사용됩니다.

역할은 **AWS 리소스**에서 사용하는 자격증명이며,
보통 **AWS EC2 리소스에 특정 정책 및 권한을 적용**할 때 사용됩니다.

<br>
### 권한 경계(Permissions Boundary)

**권한 경계**는 IAM 사용자 또는 역할에 최대 권한을 제한하는 기능입니다.<br>
권한 경계가 지정된 사용자는 넓은 범주의 정책 적용을 받더라도 **지정된 권한 경계를 초과하는 권한은 가질 수 없습니다.**

예를 들어 **'admin'** 그룹에 속한 사용자들이 **AmazonEC2FullAccess** 권한을 가진다고 할 때,
**'temp_admin'** 계정에 한해 권한 경계를 **AmazonEC2ReadOnlyAccess** 로 지정해두면
**'temp_admin' 계정은 'admin' 그룹에 속했음에도 EC2 리소스에 대해 읽기 권한**만 가집니다.

> _**[실전]** 회사는 **개발자**가 **기존에 존재하는 IAM 정책**을 **기존에 존재하는 IAM 역할에 연결**하여
> 더 빠른 실험과 민첩성을 지원하도록 허용합니다. 그러나 보안 담당자는 개발자가 **기존에 존재하는 관리자 정책을 첨부**하여
> **다른 보안 정책을 우회할 수 있다고 우려**하고 있으므로, 이를 해결하기 위한 솔루션은,_
> - _**해결**: **IAM 권한 경계**를 사용!!
> **개발자의 IAM Role** 에 **관리자 IAM Policy 연결을 명시적으로 거부**하는 **권한 경계** 설정._
> - _>> 기존에 존재하는 policy 를 role 에 연결하는 권한을 개발자가 가지고 있지만,
> **권한 경계로 인해 관리자 policy 한정으로 연결이 거부**됨!_

<br>
### 신뢰 정책(Trust Policy)

**신뢰 정책**은 **IAM 역할에서 AWS 계정 간 액세스 권한을 위임할 때** 사용됩니다.

예를 들어 개발자들이 테스트 수행을 위해 프로젝트의 프로덕션 권한을 얻을 때 사용할 수 있습니다.<br>
(본래는 프로덕션 권한이 없지만 프로덕션 계정의 역할에서 지정된 신뢰 관계를 통해 임시로 권한을 획득)

<br>
### EC2 관련

**(1)** **인스턴스 구매 옵션**은 다음과 같습니다.

- **온디맨드**: 초당 사용량 청구
- **스팟 인스턴스**: 경매 방식, 가장 저렴할 수 있으나 shutdown 의 위험 존재, 온디맨드에 비해 최대 90%까지 저렴
- **예약 인스턴스**: 1년 ~ 3년, 인스턴스 유형 및 리전 포함 일관된 인스턴스 구성, 온디맨드에 비해 최대 75% 저렴
- **savings plan**: 1년 ~ 3년 기간 동안 시간당 USD 로 일관된 사용량 약정, 초과분은 온디맨드 청구, 온디맨드에 비해 최대 66~72% 저렴
- **전용 호스트/전용 인스턴스**: 단일 테넌트 하드웨어 서버 할당. CPU 소켓, 코어가 지정되면 전용 호스트, 아니면 전용 인스턴스

**(2)** **ENI(Elastic Network Interface)** 는 인스턴스에 부착되어 네트워크 카드(랜카드) 역할을 합니다.

- **네트워크 인터페이스(ENI)**: 일종의 네트워크 카드로 IP, MAC 주소가 할당되며 보안 그룹에 연계되어 네트워크 트래픽 제어
    - 인스턴스에는 여러 ENI 가 부착될 수 있음
    - 이 말은 곧 여러 IP 주소를 부여할 수 있다는 의미!

**(3)** **EC2 배치 그룹(Placement Groups)**이란 가용영역 내 하드웨어 서버랙에서
EC2 인스턴스들을 다양한 형태로 가깝게 배치하는 것을 의미합니다.
배치 전략에 따라 서버랙 전반에 분산되도록 하거나 논리적 파티션 단위로 분할하거나 단일 서버랙에 국한되게 구성할 수 있습니다.

- **클러스터 배치그룹**: 고성능 네트워크 연결로 이루어진 인스턴스 묶음
    - 물리적으로 가깝게! 따라서 네트워크 지연시간이 매우 짧음! 고성능 컴퓨팅(HPC)에 활용
- **파티션 배치그룹**: 인스턴스 그룹을 하드웨어를 공유하지 않는 파티션 단위로 분할
    - 논리적 파티션 그룹! 서로 다른 서버랙의 하드웨어를 엮어서 파티션 구성
    - 따라서 파티션은 하드웨어를 공유하지 않으므로 하나의 하드웨어에 장애가 발생해도 다른 파티션은 영향을 받지 않음
    - 하둡 등 빅데이터 분산처리 시스템에 사용
- **분산형 배치그룹**: 인스턴스 그룹을 별개의 서버랙 단위로 구성
    - 각 분산 그룹은 서로 다른 서버랙이므로 특정 서버랙에 장애가 발생해도 다른 그룹은 안전함
    - 매우 중요하고 고가용성이 필요한 애플리케이션에 적합

**(4)** **EC2 라이프 사이클**에서 **최대절전모드**는 PC의 절전모드와 같음
    
- **라이프 사이클**: 시작, 재부팅, 중지, 종료, 최대절전모드
- **최대절전모드(Hibernate)**: RAM 에 있는 애플리케이션 상태를 저장 후 중지상태로 전환(노트북 절전모드),
메모리에서 불러오므로 부팅 속도가 빠르고 상태가 보존됨

**(5)** **타겟 그룹(Target Group)** 생성 후 **속성(Attributes)**값 세팅 시 공통적으로 **등록 취소 지연(Deregistration delay)**
값을 지정합니다.

- **등록 취소 지연(Deregistration delay)**: Auto Scaling 축소 등으로 등록 취소된 인스턴스에 연결된 request 가 있을 경우,
지정한 시간 동안 지연 후에도 연결이 유효하지 않으면 더 이상 해당 인스턴스에 request 를 보내지 않는 기능. 보통 300초로 지정
- **HTTP/HTTPS 프로토콜을 사용하는 ALB 의 속성**의 경우, **느린 시작 기간(Slow start duration)** 설정을 통해 신규 등록된 타겟에
대한 request 를 선형적으로 증가시킬 수 있고,
**Stickiness Session(고정 세션)** 을 설정해 동일 세션인 경우 동일 인스턴스에 고정적으로 클라이언트 요청이 가도록 할 수 있음
- **TCP/UDP/TLS 프로토콜을 사용하는 NLB 의 속성**의 경우, **등록 해제 시 연결 종료(Connection termination on deregistration)**
설정을 통해 등록 취소 지연이 일어나는 동안 해당 타겟에 대한 활성 연결을 NLB 로 하여금 종료하도록 만들 수 있고,
**클라이언트 IP 주소 보존(Preserve client IP addresses)**을 설정하여 모든 트래픽의 클라이언트의 IP 를 타겟에 그대로 전달할 수 있음.
**Stickiness Session(고정 세션)** 설정도 동일하게 가능

**(6)** **로드 밸런서(ELB, Elastic Load Balancer)**

- **A(Application)LB** 의 경우, **리스너 규칙 조건(IF)값**은,
    - **호스트 헤더 기반**: 지정된 호스트 요청에 대한 타겟 그룹으로 라우팅
    - **Path 기반**: 요청 URL에 따라 라우팅
    - **HTTP 헤더 기반 라우팅**
    - **HTTP request method 기반 라우팅**
    - **Query string 기반**: 쿼리 문자열의 키/값 페어 또는 값을 기반으로 라우팅
    - **Source IP 기반 라우팅**
- **N(Network)LB** 의 경우 네트워크 및 전송계층이므로 **리스너 규칙 조건(IF) 설정 없음**
    - 다만 **고정 IP(EIP) 할당**이 가능함! >> **만약 고정적인 퍼블릭 IP 할당이 필요하다면 NLB 를 고려**해야 함

**(7)** **Auto Scaling** 은 인스턴스를 자동으로 확장하고 축소하는 기능으로,
사용자가 정의한 조정 정책에 따라 개수가 조절됩니다. 혹은 서버의 로드 수에 따라서 조절도 가능합니다.

- **구성 요소**: 오토 스케일링 그룹, 시작 템플릿(AMI, 인스턴스 유형, 스크립트 등 지정), 조정 옵션(조정 정책)
- **조정 정책**: Auto Scaling 을 실행하기 위한 조건
    - **수동 조정**: 직접 연결 혹은 분리
    - **용량 제한 설정**: 최대, 최소, 원하는 용량만
    - **일정한 수의 인스턴스 유지**: 항상 현재 인스턴스 수준 유지 관리
    - **예약된 조정**: 일정을 기반으로 조정(시간 및 날짜 함수)
    - **동적 조정**: 온디맨드 기반 조정(수요 변화, 예를 들어 CPU 50%)
        - **대상 추적 조정**: **CloudWatch 지표**와 애플리케이션의 **이상적인 평균 사용률 또는 처리량(throughput) 수준 목표 값**
        지정. 오토 스케일링 그룹에 속한 인스턴스 당 **백로그 계산을 기반으로 메트릭(지표) 생성, 이 메트릭 기반으로 자동 조정**됨
        - **단계 조정**: CloudWatch 경보 생성하고 높은 임계값과 낮은 임계값 지정
        - **단순 조정**, Amazon SQS 기반 크기 조정
    - 예측 조정 사용(Predictive Scaling) > 머신 러닝을 이용하여 CloudWatch 기록 데이터 기반
- **조정 휴지(Scaling cooldowns)**: 인스턴스 증가 혹은 감소 시 처음에는 CPU 사용량이 늘어나는 등 **비정상 상황이 존재할 수 있으므로
조정 휴지 기간**을 가짐. 보통 300초며, 이 동안에는 Auto Scaling Group 은 지표값을 측정하지 않음
- **수명 주기 후크**: Auto Scaling 에서 관리되는 인스턴스는 **Lifecycle hook** 를 거치면서 **launcing or terminating** 되는데,
**훅 기간 중에 필요한 작업을 추가**할 수 있음 (ex. 로그나 실행정보를 감사시스템에 메시지(SQS)로 보내는 작업 추가하기)

**(8)** **EBS(Elastic Block Storage)**는 SSD, HDD 와 같은 하드디스크로 EC2에 부착됩니다.
인스턴스를 시작할 때 함께 생성되는 EBS 는 부트 볼륨으로, 시스템 부팅을 위해 사용됩니다.

- EC2 와 EBS 볼륨은 **같은 AZ 에 있어야** 연결 가능
- 유형: **SSD Type**(범용SSDgp2gp3, 프로비저닝된SSDio1io2), **HDD Type**(처리량최적화st1, 콜드sc1)
- AMI 가 설치되는 부트 볼륨은 범용SSD, 프로비저닝된SSD만 지원함
- **EBS 다중연결(Multi-Attach)**
    - 하나의 볼륨이 여러 EC2 인스턴스에 연결(최대 16개)
    - Nitro 기반 Linux 인스턴스 유형만 가능(동일 AZ)
    - 프로비저닝된SSD만 지원
- **스냅샷**
    - 백업된 EBS 볼륨 데이터는 **다른 AZ 또는 리전에 복사, 생성 가능**
    - **스냅샷으로부터 커스텀 AMI 이미지를 만들어 새 EC2 인스턴스 생성까지 가능함!**
    - 이 때는 설치할 OS가 설치된 부트 볼륨이어야 함
- 이미 존재하는 EBS 볼륨이 암호화되지 않았다면 **스냅샷을 이용하여 암호화된 볼륨으로 재생성** 가능

**(9)** **Instance Store** 는 가상머신인 인스턴스에 물리적으로 부착되는 **임시 블록 스토리지**로,
물리적으로 붙어있기 때문에 고성능이지만 인스턴스가 종료(혹은 최대절전모드)되면 사라지므로
**빠른 IOPs 성능의 임시저장 스토리지**를 요하는 시스템에 적합합니다.

**(10)** **EFS(Elastic File System)** 란 리눅스 환경의 EC2 인스턴스에서 연결하기 위한 **네트워크 파일 스토리지**입니다.
이것은 **인바운드 시 NFS 프로토콜 규칙을 적용하는 보안 그룹**을 지정하는 것이 특징입니다.

- **EFS**: 네트워크 파일 스토리지는 온프레미스를 포함한 여러 원격 서버에서 접속할 수 있으므로
**NFS(Network File System) 프로토콜**을 지원함
    - 보안 그룹을 통해 여러 가용영역에 존재하는 수십~수백 대의 EC2 인스턴스 연결 가능
- **스토리지 클래스 분류**
    - **표준 스토리지(Standard)**: 3개의 가용영역에 데이터 저장, 자주 액세스하는 파일 대상
    - **표준 IA(Standard Infrequent Access)**: 3개 가용영역, 자주 액세스하지 않는 파일 대상
    - **One Zone/One Zone IA**: 1개 가용영역에 자주 액세스하거나/자주 액세스하지 않는 파일 대상
    - **수명 주기 관리** 설정을 통해 자주 액세스하지 않는 파일을 다른 스토리지 클래스로 자동으로 이동시키도록 할 수 있음
- **성능 모드**: 스토리지의 I/O, 읽기 쓰기 속도 조정
    - **기본 범용 성능 모드(General Purpose Performance Mode)**: 일반적인 I/O 성능
    - **최대 I/O 성능 모드(Max ~)**: 높은 성능을 요하는 빅데이터 분석 앱 등에서 사용
- **처리량 모드**: 파일 시스템의 처리량(MiB/s) 조정
    - **기본 버스팅 처리량 모드**: 파일 용량이 커짐에 따라 처리량을 자동 확장
    - **프로비저닝된 모드**: 고정 처리량 지정
- **인스턴스 생성 후 EFS 연결하기!**
    1. **NFS 전용 보안그룹**을 생성한 후 적절한 옵션으로 **EFS 생성하면서 각 가용영역에 해당 NFS 보안그룹 연결**
    2. **EC2 인스턴스**를 생성하며 **스토리지(볼륨)의 파일 시스템을 EFS** 로 지정
        - 인스턴스 생성하며 이전에 생성한 EFS 를 바로 연결할 수 있지만, **생성 이후에 연결할 수**도 있음
        - 보안그룹을 이전에 생성한 **NFS 보안그룹의 인바운드 규칙에서 허용하는 대상**으로 지정 (보통 인스턴스의 보안그룹 혹은 IP)
    3. 생성한 EFS 에서 '연결' 을 클릭하여 **DNS를 통한 탑재** 이후 **EFS 탑재 헬퍼 사용** 혹은 **NFS 클라이언트 사용** 부분 확인
        - 인스턴스에서 **amazon-efs-utils** 패키지 설치 후 EFS 파일 시스템을 마운트(mount)
            - 마운트 정보는 앞서 확인한 명령줄 사용!

> _**[실전]** **단일 VPC** 의 **여러 가용 영역**의 **여러 EC2 인스턴스** 간에 **데이터를 공유하는 고성능 스토리지 솔루션**을
> 구축해야 합니다. 또한 **데이터를 VPC 내에서만 유지**해야 합니다.
> 이 때는 **수십~수백 대의 인스턴스 연결 및 데이터 공유**가 가능한 **EFS** 를 사용해야 합니다._
> - _**(X)** **S3** 는 여러 EC2 인스턴스 간에 데이터를 공유하는 고성능 스토리지 솔루션은 아님_
> - _**(X)** **EBS** 는 다음의 제약사항으로 인해 적절하지 않음_
>     - _**인스턴스 타입 제약** >> Nitro 기반 Linux 인스턴스만 가능(single provisioned IOPs SSD)_
>     - _**연결 인스턴스 개수 제약** >> 최대 16개_
>     - _**가용 영역 제한** >> EBS 가 존재하는 **단일 가용 영역**에 한함.
>     **EBS 복제(Replica)**로 다른 가용 영역에 생성은 가능하나,
>     **여러 AZ 의 여러 인스턴스 간 데이터 공유 스토리지 솔루션**에는 적합하지 않음_

> _**[실전]** **여러 가용 영역**의 EC2 인스턴스가 공유하는 **공유 스토리지 솔루션**이면서 수시로 변경되는 콘텐츠 데이터에 대한
> **강력한 일관성**이 요구되는 환경에서 적절한 것은 **EFS** 입니다. **NFS 파일 시스템 스토리지**이므로 변경 사항이 즉시 반영됩니다._
> - _**(X)** **Storage Gateway** 는 온프레미스 환경이 아니므로 해당되지 않는 솔루션_
> - _**(X)** **EBS** 는 단일 가용 영역이므로 부적절_
> - _**(X)** **CloudFront** 솔루션으로 **Cache-Control 헤더의 메타데이터를 no-cache** 로 설정하는 것은 **단지 캐싱 없이 콘텐츠를
> 제공하는 것**이므로 **강력한 일관성의 인스턴스 간 공유 스토리지 솔루션을 요하는 해당 이슈와는 무관**함_

<br>
### S3 및 기타 스토리지

**(1)** 오브젝트 스토리지인 **S3(Simple Storage Service)** 는 파일이 아닌 오브젝트 단위로 데이터를 저장합니다.
오브젝트에는 **키, 데이터 및 옵션 메타데이터**가 포함되어 있으며 키값으로 접근이 가능합니다.

- **S3**: 거의 무제한의 저장용량을 제공하며, **버킷**은 오브젝트 저장공간이고 **오브젝트**는 일종의 파일과 같은 객체
    - **버킷**은 **리전 단위로 생성**되며 **유일성**을 갖춰야 함
    - 개별 오브젝트의 최대 사이즈는 5TB
- **강력한 내구성**: **AWS 에서는 S3 가 99.999999999% (소수점 아래 9 아홉개) 의 내구성을 보장**한다고 함
- **버전 관리**: 동일한 이름의 객체(파일)를 업로드하면 여러 버전으로 저장됨(버전 관리 기능 활성화 필요)
- **암호화**: 데이터 암호화를 위해 **서버 측 암호화(SSE)**와 **클라이언트 측 암호화(CSE)**, **전송 중 암호화(SSL/TLS 이용)**를 사용
- **S3 버킷 정책**: 일반적으로 **버킷 정책**을 주로 사용하며, 정적 웹사이트 호스팅 시에는 퍼블릭 액세스 허용함
    - **버킷 정책**: JSON 형식의 정책으로, AWS 리소스나 특정 계정에 버킷 액세스 권한을 부여
    - **퍼블릭 액세스 차단(버킷 설정)**: 인터넷망에서 접속하는 퍼블릭 액세스를 차단하도록 할 수 있음. 버킷 기본값!
    - **ACL(액세스 제어 목록)**: AWS 계정에 버킷이나 객체 단위로 읽기/쓰기 권한 부여

> _**[실전]** 미디어 회사는 비디오 처리 애플리케이션에서 **가능한 최대 I/O 성능**과 함께 **최소 10TB 스토리지**가 필요합니다.
> 미디어 콘텐츠 저장을 위해 **내구성이 뛰어난 300TB 의 스토리지**와 **더 이상 사용하지 않는 아카이브** 미디어 저장을 위한
> 900TB 스토리지 솔루션이 필요합니다._
> - _**(O)** 최대 성능을 위한 **EC2 인스턴스 스토어** + 내구성 있는 스토리지를 위한 **S3** + 더 이상 사용하지 않는
> 아카이브를 위한 **S3 Glacier**_
> - _**(X)** **EBS** 는 충분히 빠르긴 하지만 **인스턴스 스토어에 비해 가능한 최대 I/O 성능은 아님**_
> - _**(X)** **EFS** 는 **내구성에 대한 AWS 측의 공식적인 보장은 없음**_

> _**[실전]** **이미지 업로드 웹사이트**를 운영할 때 사용자가 업로드하는 **이미지의 크기를 조정**하여 저장하되, **업로드 요청 지연 현상이
> 발생하지 않도록** 시스템을 구성하려고 합니다. 솔루션 설계자는 **가장 운영 효율적인 프로세스를 설계**해야 합니다._
> - _다양한 솔루션 구성이 가능하겠으나, **운영 효율적이려면** 업로드 자체는 **S3 를 사용하도록** 하면서
> **이미지 크기 조정 프로세스 자체는 서버리스에 가까워야** 함.(클라우드 시스템이 알아서 처리하도록)_
> - _**해결**: **원본 이미지를 S3 에 업로드**하도록 웹 서버를 구성하고 + **업로드 S3 이벤트 알림**을 구성하여 **알림이 이미지 크기 조정
> Lambda 함수를 호출**하도록 함_

**(2)** **스토리지 클래스**: S3 서비스는 저장하는 데이터의 특성이나 패턴에 따라 **스토리지 클래스**를 결정할 수 있는데,
이에 따라 비용을 적절하게 절감할 수 있습니다.

- **S3 Standard(범용)**: 짧은 지연과 많은 처리량을 제공하므로 일반적인 용도의 다양한 사례에 사용됨
- **S3 Intelligent-Tiering**: 데이터에 대한 액세스 패턴을 알 수 없거나 변화하는 경우 사용됨.
액세스 패턴을 모니터링하여 빈도가 낮으면 더 저렴한 액세스 계층으로 자동으로 이동
    - 계층 이동: **Frequent Access 계층** >> **Infrequent Access 계층** >> **Archive Access
        계층** >> **Deep Archive Access 계층**
- **S3 Standard-IA(Infrequent)**: 빈번하지 않은 액세스용. 하지만 빠른 액세스가 필요한 데이터에 적합. 최소 과금 기간 30일
- **S3 One Zone-IA**: **S3 Standard-IA(Infrequent)**와 유사하지만, 단일 가용영역에만 저장하므로 비용이 상대적으로 저렴.
대신 그만큼 가용성이 떨어짐.(다른 스토리지 클래스는 최소 3개 AZ 에 데이터를 저장함) 최소 과금 기간 30일
- **Glacier Instant Retrieval(아카이브용)**: 저렴한 비용으로 장기 보관하는 백업 용도. 분기에 한번 액세스하는 오래된 아카이브
데이터 용도로 검색은 밀리초 내에 즉시 이루어짐. 최소 과금 기간 90일
- **S3 Glacier/Glacier Flexible Retrieval(아카이브용)**: 이것은 일 년에 한번 액세스용으로 검색 시간은 몇 분 내지 몇 시간 소요됨
최소 과금 기간 90일
- **S3 Glacier Deep Archive(아카이브용)**: 가장 저렴하며 일 년에 한번 미만 액세스 및 7~10년 이상 장기 보관용으로
검색 시간은 몇 시간. 최소 과금 기간 180일

> _**[실전]** 다음의 조건에 부합하는 **가장 비용효율적인 스토리지 솔루션**을 구성하십시오._
> 1. _수백만 명의 사용자로부터 매일 총 약 1TB 의 데이터 수신, **사용자에게 12개월 전의 사용 보고서**를 제공_
> 2. _정기적 및 감사 요구 사항을 준수하기 위해 **모든 사용 데이터를 최소 5년 동안 저장**_
> - _**솔루션**: 데이터는 **S3 Standard** 저장 + 수명 주기 설정 **1년 후 데이터는 S3 Glacier Deep Archive** 로 전송 +
> 수명 주기 설정 **5년 후 데이터 삭제**_
> - _**설명**: **최초 12개월 동안은 짧은 지연과 빈번한 처리**가 예상되고, 그 이후 5년 삭제 시점 이전까지는 **가장 저렴한
> S3 Glacier Deep Archive** 에 저장_

> _**[실전]** 전 세계의 어플리케이션 사용자의 파일 업로드 및 다운로드 **속도를 빠르게** 하려면,
> S3 콘솔에서 **S3 Transfer Acceleration(S3TA)** 을 구성합니다._
> - _**S3TA** 는 **더 큰 용량의 객체를 장거리 전송하는 속도를 높이기** 위해 고안되었음_
> - _**S3TA** 는 트래픽이 글로벌로 분산된 **엣지 로케이션**이나 **AWS 백본 네트워크**로 라우팅되게 하거나,
> **네트워크 프로토콜 최적화**를 이용해 전송 퍼포먼스를 향상시킵니다._
> - _**S3TA** 사용시에는 표준 엔드포인트가 아닌 **S3 Accelerate endpoint** 를 사용하도록 합니다.
> (**<bucket>.s3-accelerate.amazonaws.com**)_

**(3)** **객체 수명 주기 관리(Lifecycle Policy)**: 오브젝트마다 스토리지 클래스를 일일히 지정할 수는 없으므로, 이를 비용효율적으로
관리해주는 수명 주기 관리 기능을 사용할 수 있습니다.

- 버전 관리가 활성화된 경우, 버전별 수명 주기 정책을 적용할 수 있음
    - ex. **S3 Standard >> (30 days) >> S3 Standard-IA >> (60 days) >> Glacier >> (365 days) >> Delete!**
- Amazon S3 Analytics 로 데이터 액세스 패턴을 분석 후 IA 스토리지 클래스로 옮길 시점을 알려줌

**(4)** S3 에서 **정적 웹사이트를 호스팅**하면 EC2 로 동적 사이트를 호스팅하는 것보다 훨씬 간편하고 저렴하게 운영할 수 있습니다.
이 때는 정적 호스팅을 위한 **인덱스 및 에러 페이지와 기본적인 리소스를 버킷에 업로드**하고, **퍼블릭 액세스 차단을 해제**하도록 합니다.

**(5)** S3 의 **서버 액세스 로깅(Access Logs)**을 활성화하면 버킷의 모든 활동이 로그파일로 저장되어 감사 목적으로 활용할 수 있습니다.
이 때 **로그파일 저장소를 같은 버킷에 두지 말아야** 합니다.(무한루프의 위험) 따라서 액세스 로그 저장용 버킷을 따로 생성해 두면 좋습니다.

**(6)** **S3 Replication(복제 규칙)**이란 버킷 간에 객체를 자동으로 복제하는 기능입니다. 이를 위해 원본과 대상 버킷 모두 버전관리가
활성화되어 있어야 합니다.(다른 계정 버킷간에도 가능)

- **교차 리전 복제(CRR, Cross Region Replication)**: 서로 다른 리전의 버킷으로 복사.
    - 예를 들어, 한국의 객체를 미국에서 빠르게 볼 수 있도록 복제 또는 재해복구의 목적
- **동일 리전 복제(SRR, Same Region Replication)**: 동일 리전 복사.
    - 예를 들어, 동일 데이터를 사용하는 프로덕션과 테스트 계정 간의 복제 혹은
    - 법적 준수사항으로 같은 리전 안에 데이터 복사본을 만들어 놓아야 하는 경우

**(7)** **S3 Glacier Vault Lock** 을 사용하면 저장된 파일을 삭제하거나 편집하지 못하도록 정책적으로 잠글 수 있습니다.
이를 위해 **Vault Lock 정책**을 생성해야 합니다.

- **사용목적**: 데이터 보관 규정 준수 정책이 있는 경우
- **S3 Glacier Vault**: 아카이브 데이터를 저장하는 컨테이너
- **WORM(Write Once Read Many)** 모델을 적용

**(8)** **S3 Object Lock 객체 잠금** 기능을 사용하면 일정 시간 또는 무기한으로 객체가 삭제되거나 덮어쓰이지 않고 읽기만 가능하도록
할 수 있습니다.

- S3 객체 잠금을 사용하면 **write once, read many(WORM) 모델**을 사용하여 객체를 저장함
- **보관 모드**:
    - **거버넌스 모드(governance mode)**: **대부분의 사용자가 객체를 삭제하지 못하도록 보호**되지만,
    필요에 따라 **일부 사용자가 보관 설정을 변경하거나 객체를 삭제하는 권한을 부여받을 수 있음**
    - **규정 준수 모드(compliance mode)**: 보호되는 객체 버전은 **루트 사용자 포함 어떤 사용자도 덮어쓰거나 삭제할 수 없음**.
    **규정 준수 모드에서 객체를 잠그면 보관 모드를 변경하거나 보관 기간을 줄일 수 없음**.
    따라서 특정 보관 기간 동안 객체를 잠글 때 이 모드를 사용

> _**[실전]** 발송된 모든 이메일을 **Amazone S3** 에 **12개월 동안 저장**하고자 할 때 구성 단계는,_
> - _**(1) 12개월 후에 메시지를 삭제하는 S3 수명 주기 구성을 생성**하고_
> - _**(2)** 업로드된 이메일 메시지에 대해 **규정 준수 모드에서 S3 객체 잠금을 사용**_

**(9)** **Storage Gateway** 란 온프레미스 데이터 센터의 데이터와 AWS 클라우드 스토리지를 연결하는 서비스로,
**S3 파일 게이트웨이**, **FSx 파일 게이트웨이**, **볼륨 게이트웨이**, **테이프 게이트웨이**가 있습니다.
파일 백업, 클라우드 파일 저장소, 재해복구 등의 용도로 사용하며, 이를 통해 온프레미스 스토리지 비용 절감 효과가 있습니다.

- **하이브리드 클라우드 스토리지**: 온프레미스 NFS 서버와 AWS 클라우드 스토리지를 연결하므로 **하이브리드 클라우드 스토리지**로도 지칭함
- **AWS Direct Connect** 환경을 구축하여 비공개의 더 빠른 액세스 가능
- 온프레미스의 **로컬 캐시 기능**을 통해 자주 사용하는 데이터 보관 가능
- **파일 게이트웨이**: 온프레미스 NFS 스토리지와 AWS 클라우드 스토리지(S3, Windows FSx) 연결. 백업, 추가적인 저장, 재해복구 등의 목적
- **볼륨 게이트웨이**: 온프레미스에서 iSCSI 연결이 가능한 블록 스토리지 제공. 기본 볼륨 데이터는 S3 에 저장되며, 이 볼륨은
EBS 스냅샷으로 저장 및 AWS Backup 서비스로 백업 가능
    - **캐싱볼륨**: 기본데이터는 S3 에 저장하고 자주 액세스하는 일부 데이터만 로컬 캐싱에 저장, 캐시를 통해 액세스
    - **저장볼륨**: 모든 데이터를 로컬에 저장 후 AWS 에 비동기식 백업, 로컬에 백업세트가 저장된 효과

> _**[실전]** **Storage Gateway** 는 **온프레미스 데이터 센터에 NFS 서버**가 존재할 때,
> 온프레미스 애플리케이션의 데이터에 대한 **짧은 지연 시간 액세스를 유지**하면서
> 애플리케이션 데이터를 온프레미스에서 **AWS 클라우드로 마이그레이션**해야 하는 경우 사용합니다._
> - _여기서 마이그레이션이라고 했지만 **엄밀히는 지속적인 연결로 파일을 전송**하는 것임_
> - _**짧은 지연 시간 액세스 유지**를 위해서는 **Storage Gateway 의 S3 File Gateway 의 온프레미스 캐싱** 기능을 사용.
> 디렉토리 액세스 빈도에 따라 로컬 캐시를 AWS 스토리지와 동기화할 수 있음_

> _**[실전]** Storage Gateway 구성을 위해 **온프레미스에 클라이언트 환경**을 구성해야 하지만 **컴퓨팅 리소스가 없는
> 작은 데이터 클로짓(small room)**인 경우, **하드웨어 어플라이언스**를 설치하여 AWS 에 연결할 수 있도록 합니다._

![AWS Storage Gateway](https://d1.awsstatic.com/pdp-how-it-works-assets/
product-page-diagram_AWS-Storage-Gateway_HIW@2x.6df96d96cdbaa61ed3ce935262431aabcfb9e52d.png)

**(10)** **FSx for Lustre** 는 리눅스 환경을 위한 **고성능 병렬 스토리지 시스템(DFS, Distributed File System)**으로
머신 러닝, 빅데이터 등 고성능 컴퓨팅(HPC, High Performance Computing)을 위해 사용할 수 있습니다.

**(11)** **FSx for Windows File Server** 는 윈도우 서버를 위한 파일 공유 서비스이며,
리눅스 파일 공유 스토리지 서비스인 **EFS(Elastic File System)** 와 비교할 수 있습니다.
EFS 가 NFS 프로토콜을 사용하는 반면 이것은 **SMB 프로토콜을 사용**하며,
EFS 와 같이 네트워크 파일 공유 서비스이기 때문에 온프레미스 서버에서도 접근할 수 있습니다.

**(12)** **Snow Family** 는 데이터를 네트워크가 아닌 물리적인 장치에 저장하여 전송할 수 있는 디바이스입니다.
오프라인 데이터 전송 방식이므로, 네트워크 연결이 안정적이지 못한 환경이나
강력한 보안을 요하거나 데이터센터 자체의 마이그레이션을 위해 사용할 수 있습니다.

**(13)** **AWS DataSync** 는 완전 관리형 데이터 마이그레이션 서비스로,
온프레미스와 AWS 간 또는 AWS 스토리지 서비스 간 데이터 전송 및 복제를 자동화할 수 있습니다.

- **온프레미스 서버파일** >> **(SMB, NFS protocol)** >> **AWS S3, EFS, FSx for Windows
or S3 Glacier archiving** 자동화
- **Direct Connect** 하이브리드 클라우드 환경을 구성하여 S3 혹은 EFS 에 동기화할 수 있음
- 대용량 전송, 전송 중 및 전송 종료 시 데이터 무결성 확인 및 암호화 가능하며, 예약된 일정에 따라 자동 스케줄링 가능하며
비용은 전송하는 데이터에 대해서만 부과됨
- **DataSync** 는 효율성 중심으로 특별히 설계된 데이터 전송 프로토콜로,
오픈 소스 기반 데이터 전송 솔루션보다 10배 빠른 속도로 대용량 데이터를 일회성 또는 주기적으로 전송 가능
- **DataSync** 는 온프레미스의 특정 시점 데이터를 AWS 스토리지에 마이그레이션하는 반면(스케줄링 자동화 가능),
**Storage Gateway** 는 AWS 와 지속적인 연결을 유지함
- 따라서 초기 마이그레이션은 **DataSync** 로 하고 이후 지속적 연결은 **Storage Gateway** 의 S3 파일 게이트웨이로 구성함
- **환경 구성 방법**: 온프레미스 데이터 센터에 DataSync 에이전트가 설치된 VM 을 배포 -> 이 VM 이 NFS 스토리지에 대한 클라이언트
역할을 하며 데이터 전송을 가속화함

> _**[실전]** **DataSync** 는 **마이그레이션** 서비스로,
> 온프레미스와 AWS 스토리지 간 **지속적 연결** 서비스인 **Storage Gateway** 와는 차이가 있음_

> _**[실전]** **DataSync** 는 **스케줄에 따라 마이그레이션이 동기화**되므로,
> 특정 시점의 **스냅샷**을 AWS 에 복제하는 배치 작업을 예약할 필요가 없음_

**(14)** **AWS Backup**: AWS 는 다양한 스토리지 서비스의 백업을 중앙집중식 서비스로 제공합니다.
다만 EBS 는 자체적인 스냅샷/백업 시스템을 가지고 있습니다.

- 백업 대상: **FSx, EFS, DynamoDB, EC2, EBS, RDS, Aurora, Storage Gateway(Volume Gateway), VMware 가상머신**
- 마찬가지로 백업 일정, 보존, 모니터링, 수명주기 관리가 가능하며 액세스 정책 및 암호화 등의 기능을 사용할 수 있음
- 교차 리전 및 계정 백업 가능
- 리소스 태그 기반으로 백업정책 구성 가능

<br>
### 글로벌 전송

**(1)** 글로벌 배포 서비스인 **CloudFront** 는 콘텐츠 전송 네트워크 서비스,
즉 AWS 에서 제공하는 **CDN(Contents Delivery Network)** 서비스입니다.
전 세계에 배포된 200개 이상의 엣지 로케이션을 이용해 가까운 지역에 콘텐츠를 빠르게 전송합니다.

- 지역별로 분산 배포되어 오리진 서버의 부하를 줄일 수 있고,
오리진에서 CloudFront 로 전송되는 비용은 부과되지 않으므로 비용 절감 효과가 있음
- 사용자 request header 값에 따라 서로 다른 버전(언어)의 콘텐츠를 캐싱하여 제공할 수 있음
- **가격 등급**: **전체 가격 등급(Price Class All) > 가격 등급 200 > 가격 등급 100 순으로 저렴**하면서
**전송 커버 지역이 제한됨(전송 속도가 상대적으로 느림)**
- **Origin Group**: Primary, 보조 오리진으로 그룹을 구성하여 고가용성 확보
- **Lambda@Edge**: CloudFront 엣지에서 람다 함수 실행이 가능
    - ex. A/B 테스트를 위해 사이트의 다양한 버전을 볼 수 있도록 쿠키를 검사하고 URL 을 다시 작성

**(2)** **CloudFront 의 배포** 예제로는,
**오리진 S3 버킷으로 정적 퍼블릭 웹사이트를 생성하고 그것을 토대로 CloudFront 배포를 생성**하는 것이 있습니다.

> _**[실전]** **S3 호스팅 + CloudFront**: 오리진 S3 버킷에 대한 부하를 줄이고,
> 글로벌 단위로 콘텐츠를 제공하는 애플리케이션 서비스를 배포_
> - _원본 부하를 줄이려면 사실상 **원본에 대한 직접적 액세스를 제한**해야 하므로,_
> - _아래 CloudFront 보안에서 **OAI 접근 제어**를 적용하고 원본과 연계된 CloudFront 의 도메인을 고객에게 제공해야 함_

> _**[실전]** **CloudFront** 배포 목적이 각 지역별 **HTTP 프로토콜의 콘텐츠 제공 최적화**라면,
> **AWS Global Accelerator** 의 목적은 **TCP/UDP 계층 수준에서 라우팅 경로 최적화(Anycast)**에 있음._
> - _즉, 전자는 가까운 지역에서 빠른 콘텐츠 제공의 목적이고, 후자는 가장 최적화된 경로 찾기의 목적임_

> _**[실전]** CloudFront 로 배포된 S3 정적 호스팅의 **가용성을 높이기 위해서는**, **(1) S3 리전 간 복제로 다른 리전에
> 복제본을 생성**하고, **(2) 복제본 리전을 바라보는 오리진을 생성**하고, **(3) 기존 오리진 버킷을 기본으로 하고
> 복제본 오리진 버킷을 보조로 하는 CloudFront 오리진 그룹을 설정**하면 됩니다.**_

> _**[실전]** **정적 및 동적 콘텐츠**를 전 세계 사용자에게 **가능한 한 빨리 제공**하려면
> **단일 리전에 인프라(ELB+EC2 등)를 구축**하고 **CloudFront 를 구성하여 해당 리전의 ELB 를 오리진으로 설정**하면 됩니다._
> - _**(X) 두 AWS 리전에 인프라를 구축**한다 해도 **수많은 엣지 로케이션에서 콘텐츠를 제공하는
> CloudFront** 보다 빠르거나 효율적일 수 없음_
> - _**(X) 동적 콘텐츠** 또한 **ELB 에서 직접 제공**하는 것보다 **CloudFront 오리진으로 설정해서 제공하는 것**이 빠름.
> 엣지 로케이션은 AWS 자체의 고속 네트워크를 사용하기 때문임_

**(3)** **CloudFront 의 보안**은 다음과 같습니다.

- **뷰어/오리진 프로토콜 정책**: 뷰어 프로토콜과 오리진 프로토콜 각각에 허용되는 프로토콜을 지정할 수 있음(HTTP/HTTPS 등)
- **OAI(Origin Access Identity)**: CloudFront 는 OAI 를 가지고 있으며, 오리진인 S3 버킷에서는 **OAI 가 있는 request 만 연결
허용**시키도록 설정 가능. 이 경우 OAI 없이 직접 버킷에 접속한다면 퍼블릭 액세스라고 할지라도 연결 거부됨
- 추가적인 보안 액세스
    - **Signed URL, Signed Cookies**: URL 은 단일 리소스, 쿠키는 여러 파일 접속시 인증용
    - **지역 제한**: 법률적인 사항으로 국가별 저작권이 다른 경우, 화이트리스트 혹은 블랙리스트 지역제한 옵션 선택
    - **WAF(Web Application Firewall)** 또는 **AWS Shield** 와 결합해 DDoS 공격 방어
    - **필드 레벨 암호화**: 사용자가 제출한 민감정보를 CloudFront 차원에서 비대칭 암호화,
    프라이빗 키를 가진 오리진 애플리케이션에서 복호화하여 사용

> _**[실전]** S3 호스팅 시, 회사의 보안 정책에 따라 모든 웹 사이트 트래픽을 **AWS WAF** 에서 검사해야 하는 경우,
> **"트래픽 ==> WAF + CloudFront + S3 origin"** 형태로 구성_
> - _**WAF ACL** 은 CloudFront 를 대상으로 생성되고, 모든 트래픽이 이 WAF 를 거치려면 CloudFront 를 거치도록 해야함_
> - _이를 위해 **S3 오리진에 직접적인 액세스는 원천적으로 막아야** 함
> -> S3 오리진 정책에서 **연계된 CloudFront OAI 만 허용하도록 지정**해야 함_
> - _**(X) WAF <==> S3 origin 직접 설정은 불가능함**_
> - _**(X) S3 에 보안 그룹(SG) 적용은 불가능함**_
> - _**(X) CloudFront 에 IP 특정도 불가능함**_
> ![WAF+CloudFront+S3 image from xp-cloud.jp](https://s3-ap-northeast-1.amazonaws.com/
> xp-wp-content/blog/wp-content/uploads/2016/07/13113012/66c19942ab4ba346fdb64ccc04cde373.png)

**(4)** **Global Accelerator** 는 글로벌 서비스로써, 요청을 보낸 사용자로부터 가장 가까운 위치로 트래픽을 라우팅하여
인터넷 대기시간을 줄이고 전송 성능을 향상시키는 서비스입니다.

- **2개의 Anycast 방식 고정 IP** 할당
- 네트워크 트래픽을 가장 가까운 노드로 전송하는 **Anycast** 라우팅 방식을 사용
- 라우팅 대상은 EIP, EC2, ELB(ALB, NLB) 등의 엔드포인트이고,
Health Check 기능을 통해 서버 장애 발생 시 다른 서버로 라우팅하도록 할 수 있음
- **엣지 로케이션**을 사용하는 것은 **CloudFront**와 같으나,
CloudFront 가 **HTTP 프로토콜로 콘텐츠(페이지, 이미지, 비디오 등)를 캐시**하는데 사용되는 것에 반해
**Global Accelerator** 는 **TCP/UDP 프로토콜 차원에서 최적화된 경로를 찾는데** 사용됨

> _**[실전]** 전 세계의 기자는 **RTMP 프로토콜** 방식의 **라이브 스트림**을 **AWS 에서 호스팅되는 방송 시스템 솔루션**으로 보내고,
> 솔루션은 **브로드캐스팅 시스템에 대한 가속화된 TCP 연결**을 다시 제공하는 구조입니다._
> - _**문제**: **기자**에게 **최고 품질의 스트림**을 보낼 수 있는 솔루션을 설계하려면?_
> - _**해결**: **TCP/UDP 전송 계층(4 Layer)**의 RTMP 프로토콜을 사용하고 **가속화된 TCP 연결 브로드캐스팅**을 지원해야 하므로,
> **Global Accelerator** 를 사용해야 함_
> - _**(X) CloudFront** 는 CDN 서비스로 **HTTP 계층의 콘텐츠 제공**에 적합한 솔루션._

<br>
### 데이터베이스

**(1)** **RDS** 는 AWS 관계형 데이터베이스 서비스이며,
**Aurora**, **PostgreSQL**, **MySQL**, **MariaDB**, **Oracle**, **SQL Server** 등의 데이터베이스를 사용할 수 있습니다.

- **스토리지 유형**: **범용 SSD 스토리지**, **프로비저닝된 IOPS SSD 스토리지**, **마그네틱 스토리지**
- **백업**
    - **자동백업**: RDS 는 DB 트랜잭션 로그를 5분마다 백업, 백업 보존기간은 1일~최대 35일까지 설정 가능
    - **스냅샷**: 수동으로 스냅샷 생성, 스냅샷은 별도의 보존기간 없음
- **보안**: **보안그룹(SG) 적용**, **SSL/TLS 를 활용한 전송 중 암호화**, **KMS 키를 사용한 저장 중 암호화**
    - **암호화되지 않은 DB 인스턴스 암호화**: **스냅샷을 활용해 인스턴스를 새로 생성하면서 KMS 암호화 체크!**
    - **RDS Audit Logs** 기능을 사용해 보안 감사에 활용 (장기 보관을 위해 CloudWatch Logs 에 보낼 수 있음)
- **읽기 전용 복제본(Read Replica)**: 사본 DB 는 읽기만 가능, 읽기 쿼리 성능 향상
- **다중 AZ(Multi-AZ)**: **고가용성** 확보, **재해 복구 용도**, **원본 DB 장애 시 다른 AZ 의 복제 DB 를 사용하여 내구성** 확보
- **RDS Custom** 은 사용자가 필요로 한다면 데이터베이스뿐 아니라 OS 에 대한 관리 권한도 가짐
    - ex. 사용자 지정 DB 및 OS 패키지 설치, 특정 DB 설정 구성, 파일 시스템 구성, 자체 라이선스 관리 등
- **RDS Proxy**: 중간에 프록시 서버가 붙어 데이터베이스와 connection pooling 하고 그것을 여러 애플리케이션이 공유하도록 하는 기능.
프록시의 커넥션 수를 제어하고 공유되므로 데이터베이스 리소스를 효율적으로 사용함

> _**[실전]** RDS PostgreSQL DB 인스턴스 사용 환경에서, **매월 초** 회계 마감 기간 동안 회계사가 높은 사용량으로 인해
> **DB 성능에 영향을 미치는 대규모 쿼리**를 실행합니다. **최소한의 노력**으로 이 쿼리가
> 웹 애플리케이션에 미치는 **영향을 최소한으로** 줄이는 솔루션은?_
> - _**(O)** **읽기 전용 복제본**을 만들어 **보고서 트래픽을 여기에 연결**. Read Replica 는 **원본에 영향 없이
> 읽기 쿼리 성능을 향상**시키는 용도_
> - _**(X)** **다중 AZ** 데이터베이스는 **고가용성** 확보, **재해 복구**를 위한 용도로 읽기 성능 향상에 적절하지 않음_
> - _**(X)** **교차 리전 읽기 전용 복제본**은 리전이 달라 지연 시간이 증가할 수 있어 부적절. **동일 리전의 Read Replica** 면 됨_

**(2)** **Aurora** 는 RDS 호환형 관계형 데이터베이스로, **AWS 에서 제공하기 때문에 저렴한 비용에 뛰어난 성능**을 나타냅니다.
또한 Read Replica, Backup, Security 등 기본적인 RDS 기능들을 그대로 제공합니다.

- **Aurora**: 개별 DB 인스턴스 기반이 아닌 **여러 인스턴스를 하나로 운영하는 클러스터 DB 기반**으로 운영되어
다른 RDS 보다 **속도는 3~5배 빠름**
- **Aurora DB 클러스터**: 하나 이상의 **DB 인스턴스**와 이 인스턴스의 데이터를 관리하는 **클러스터 볼륨**으로 구성.
Aurora DB 클러스터는 기본 DB 인스턴스에 더해 **최대 15개 Aurora 복제본**을 구성.(복제본은 읽기만)
- **Aurora 복제본(Replica)**: Read Replica. 3개 가용영역에 6개의 데이터 사본으로 구성되어 고가용성 확보.
마스터 DB 장애시 최대 30초 이내에 복제본 중 하나가 기본 DB 인스턴스 역할로 변경되는 Failover 기능 제공.
- **Aurora Auto Scaling**: 최대 15개 이내에서 복제본 수를 자동으로 조정 가능
- **Aurora 글로벌 데이터베이스**: 다른 리전에 복제하여 RTO 1분 이내에 재해복구 용도

- **Aurora Database Cloning**: 원본과 동일한 **복제본 Aurora DB 클러스터를 생성(Staging DB 등)**.
스냅샷을 만들고 복원하는 것보다 빠르고 비용효율적임.
- **Aurora Machine Learning**: 머신러닝을 위해 쿼리로 데이터를 가져와
Amazon SageMaker 또는 Amazon Comprehend 서비스와 통합하여 사용.
- **Aurora 멀티 마스터 클러스터**: 단일 쓰기 전용 마스터 클러스터 혹은 멀티 마스터 클러스터를 활용. 멀티는 모든 인스턴스가 쓰기 가능
- **Aurora Serverless**: DB 인스턴스 운영 및 용량을 수동으로 관리하지 않고, 사용량에 따라 자동으로 확장 혹은 축소하는 기능.
사용한 만큼만 용량 초당 요금으로 지불하므로 DB 사용빈도가 낮은 애플리케이션에 적합

**(3)** **ElastiCache** 는 **인메모리 데이터 스토어**로 1밀리초 미만의 빠른 응답이 필요한 애플리케이션에서 사용합니다.
코드 변경이 필요하며 세션 스토어, 게임 리더보드, 스트리밍 및 분석과 같이 내구성이 필요하지 않는 기본 데이터 스토어로 사용됩니다.

- **ElastiCache**: 오픈소스 인메모리 데이터베이스 솔루션인 **Redis** 또는 **Memchched** 두 가지 유형을 지원
- 인메모리인 만큼 **비용이 높아 일부분이면서 빠른 성능을 요하는 휘발 데이터**에 사용됨
- **RDS Read Replica VS ElastiCache**: **읽기 복제본**은 원본과 지속적으로 동기화되기 때문에 계속 변경되는 쿼리의 읽기 성능 향상에
적합하며, **ECache** 는 캐싱의 목적이므로 동일한 데이터를 빠르게 읽는 속도지향적입니다.(**자주 변경되는 데이터에는 적절하지 않다는 의미**)

**(4)** **DynamoDB** 는 NoSQL 데이터베이스 서비스로 **키-값 문서 데이터 모델**을 지원합니다. 또한 **서버리스 서비스**라 용량에 맞게
자동으로 확장 및 축소(Auto Scaling)하므로 관리 및 운영 오버헤드가 최소화되며, **한 자리 밀리초의 매우 빠른 응답과
초당 수백만개 이상의 request 처리성능을 제공**합니다.

- **DynamoDB Streams**: 테이블에 저장된 항목에 발생하는 변경사항을 캡쳐하여 **Kinesis Data Stream** 으로 보내거나
**Lambda 로 트리거하여 Amazon SNS 로 전송**하는 등의 이벤트 알림 생성 가능
- **읽기 일관성**: **최종적 일관된 읽기(기본값)**는 읽기 처리량을 최대화하여 가장 최근 쓰기 결과를 반영하지 못할 수도 있음. 반대로
**강력한 일관된 읽기**는 읽기 전 성공적인 응답을 수신한 모든 쓰기를 반영한 결과를 반환하도록 하여 상대적으로 느리고 용량을 많이 사용합니다.
- **Amazon S3 와 통합**: **Export to Amazon S3(내보내기)** 혹은 **Import to Amazon S3(가져오기)** 가 가능하며,
데이터 형식은 JSON, Amazon Ion 텍스트 혹은 CSV 가능합니다.

> _**[실전]** **DynamoDB** 는 애플리케이션에서 사용자 데이터 등 **짧은 대기 시간으로 엑세스**해야 하는
> **Json 타입 문서** 저장을 위해 사용됩니다. 또한 **서버리스이기 때문에 비용효율적**입니다._

> _**[실전]** **DynamoDB TTL** 기능 활용하기 >> 시간이 지남에 따라 테이블의 크기가 커지기 때문에 **더 이상 필요하지 않은 데이터를
> 삭제**해야 하는 경우, 가장 비용효율적인 방법은 DynamoDB 의 **TTL 기능을 활용하는 것**입니다._
> ### _DynamoDB TTL(Time to Live)_
> - _**TTL** 을 사용하면 **아이템별 타임스탬프를 정의하여 만료시점을 결정**할 수 있음_
> - _TTL 타임스탬프가 만료된 후, DynamoDB 는 **쓰기 처리량을 전혀 소비하지 않고 48시간 이내**에 **테이블에서 항목을 삭제**함_
> - _**TTL 활성화**: 콘솔에서 **Enable TTL** 이후, 지정한 **속성명(Attribute name)**에 해당하는 **속성-속성값**을
> 새로 생성되는 아이템에 추가하도록 애플리케이션을 확장_
> - _여기서 **속성값**이 TTL 만료기준으로 사용되므로, **숫자 형식의 Epoch 타임스탬프 값**을 넣어야 함
> (ex. { 'expirationTime': 1572268323 })_
> - **주의할 점**:
> 48시간 이내에 삭제된다 했으므로, **읽기 작업 수행 시 현재의 타임스탬프보다 만료값이 큰 경우만 가져오도록 필터**하는 것이 권장됨

**(5)** 그 외 데이터베이스로 **DocumentDB(MongoDB 호환, JSON)**, **Keyspaces(Cassandra 호환, Wide Column 모델, 대규모 산업용)**,
**Neptune(그래프 데이터베이스, Node 간 관계, 소셜 네트워킹)**, **Quantum Ledger Database(QLDB, 원장 레코드 DB, 은행거래)**,
**Timestream(time series, 시계열 DB, IoT 센서기록)** 이 있습니다.

**(6)** **Database Migration Service(DMS)** 서비스를 활용해 온프레미스-AWS 혹은 AWS 내에서
원본 DB 를 사용하는 중에도 마이그레이션이 가능합니다. 이 기종의 DB 인 경우 **Schema Conversion Tool(SCT)** 를 사용해 스키마를
마이그레이션 대상에 적합하게 변환할 수 있습니다. 마이그레이션 작업을 위해서는 데이터를 옮기기 위한 **중간 복제 인스턴스를 생성**해야 합니다.

<br>
**<a href="{{ site.github.url }}/cloud/2023/02/24/aws-certificate02" target="_blank">[다음글]</a>**
